{"cells":[{"cell_type":"code","execution_count":33,"metadata":{"id":"P-mO2T97JFcc"},"outputs":[],"source":["\n","path = 'C:/dataset'"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"f6aSkgS8J7WH"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.models as models\n","import math\n","import cv2"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"aeCqL7lzLFwm"},"outputs":[],"source":["categories = ['train', 'test', 'val', 'auto_test'] # 전처리된 데이터셋을 훈련용, 평가용, 검증용으로 구분\n","data_dir = path+'/osteoarthritis/'\n","# device = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu') # Mac OS\n","device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"tMT7NjG9KrZJ"},"outputs":[],"source":["def resize_image(img,size=(128,128)):\n","    return cv2.resize(img,size)\n","\n","def he_img(img):\n","    return cv2.equalizeHist(img)\n","\n","def clahe_image(img):\n","    clahe = cv2.createCLAHE(clipLimit=2.,tileGridSize=(8,8))\n","    cl_img = clahe.apply(img)\n","    return cl_img\n","\n","def denoise_img(img):\n","    return cv2.fastNlMeansDenoising(img,None,30,7,21)\n","\n","def normalize_img(img):\n","    return cv2.normalize(img,None,0,255,cv2.NORM_MINMAX)\n","\n","def detect_edge(img):\n","    return cv2.Canny(img,100,200)\n","\n","def blur_img(img):\n","    return cv2.GaussianBlur(img,(5,5),0)\n","\n","def find_contour(img):\n","    ret, thresh = cv2.threshold(img, 127, 255, 0)\n","    contours, hiearchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","    return contours"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["import os\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n","import matplotlib.pyplot as plt\n","from sklearn.utils import shuffle\n","\n","# # Data augmentation settings\n","# datagen = ImageDataGenerator(\n","#     rotation_range=3,\n","#     width_shift_range=0.05,\n","#     height_shift_range=0.05,\n","#     shear_range=0.05,\n","#     zoom_range=0.05,\n","#     fill_mode='nearest'\n","# )\n","\n","# def augment_images(data_dir, label, augment_count=600):\n","#     label_path = os.path.join(data_dir, 'train', str(label))\n","#     augmented_dir = os.path.join(label_path, 'augmented')\n","#     os.makedirs(augmented_dir, exist_ok=True)\n","\n","#     img_names = os.listdir(label_path)\n","#     img_names = [name for name in img_names if os.path.isfile(os.path.join(label_path, name))]\n","#     generated_count = 0\n","\n","#     while generated_count < augment_count:\n","#         img_name = np.random.choice(img_names)\n","#         img_path = os.path.join(label_path, img_name)\n","#         try:\n","#             img = load_img(img_path, color_mode='grayscale', target_size=(224, 224))\n","#             img = img_to_array(img)\n","#             img = img.reshape((1,) + img.shape)\n","\n","#             for batch in datagen.flow(img, batch_size=1, save_to_dir=augmented_dir, save_prefix='aug', save_format='png'):\n","#                 generated_count += 1\n","#                 break  # 한 장만 생성하고 반복문 탈출\n","#         except PermissionError:\n","#             print(f\"Permission denied: Unable to access file {img_path}\")\n","#         except Exception as e:\n","#             print(f\"Error processing file {img_path}: {e}\")\n","\n","# # Augment images in label 4\n","# # data_dir = path+'/osteoarthritis/train/'  # 적절한 데이터 디렉토리로 변경\n","# augment_images(data_dir, 4)\n","\n","# # Display augmented images\n","# augmented_img_paths = os.listdir(os.path.join(data_dir, 'train', '4', 'augmented'))\n","# augmented_img_paths = shuffle(augmented_img_paths)[:6]  # 무작위로 6개 선택\n","\n","# for i, img_name in enumerate(augmented_img_paths):\n","#     img_path = os.path.join(data_dir, 'train', '4', 'augmented', img_name)\n","#     img = load_img(img_path, color_mode='grayscale', target_size=(128, 128))\n","#     plt.imshow(img, cmap='gray')\n","#     plt.title(f'Augmented Image {i + 1}')\n","#     plt.show()\n"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"_XY2BWU-K4xp"},"outputs":[],"source":["def load_data(data_dir):\n","    images = []\n","    for img_name in os.listdir(data_dir):\n","        img_path = os.path.join(data_dir, img_name)\n","        if os.path.isfile(img_path):  # 파일인지 확인\n","            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","            if img is not None:  # 이미지가 정상적으로 로드되었는지 확인\n","                img = resize_image(img)\n","                img = clahe_image(img)\n","                img = normalize_img(img)\n","                images.append(img)\n","    prepared_data = np.array(images)\n","    return prepared_data\n","\n","def load_and_augment_data(data_dir, label):\n","    label_path = os.path.join(data_dir, 'train', str(label))\n","    augmented_dir = os.path.join(label_path, 'augmented')\n","\n","    images = []\n","    # Load original images\n","    for img_name in os.listdir(label_path):\n","        if img_name.endswith('.png'):\n","            img_path = os.path.join(label_path, img_name)\n","            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","            if img is not None:\n","                img = resize_image(img)\n","                img = clahe_image(img)\n","                img = normalize_img(img)\n","                images.append(img)\n","    \n","    # Load augmented images\n","    if os.path.exists(augmented_dir):\n","        for img_name in os.listdir(augmented_dir):\n","            img_path = os.path.join(augmented_dir, img_name)\n","            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","            if img is not None:\n","                img = resize_image(img)\n","                img = clahe_image(img)\n","                img = normalize_img(img)\n","                images.append(img)\n","    \n","    return np.array(images)\n","\n","# 증강 or 클래스 별 동일한 숫자\n","# 전체적으로 분류할 때 비율을 맞춰보는게..\n","# 증강(rotation, zoomin)\n"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115869,"status":"ok","timestamp":1717738329831,"user":{"displayName":"이규원","userId":"12166977002529024931"},"user_tz":-540},"id":"qqDsPg2gK_CZ","outputId":"de9576f3-1c50-4d90-879c-12db48aabb17"},"outputs":[],"source":["# 각 카테고리와 라벨에 따라 이미지를 처리\n","all_data = {}\n","for category in categories:\n","    category_path = os.path.join(data_dir, category)\n","    all_data[category] = {}\n","    for label in range(3):\n","        if category == 'train' and label == 2:\n","            processed_img_list = load_and_augment_data(data_dir, label)\n","        else:\n","            label_path = os.path.join(category_path, str(label))\n","            if os.path.isdir(label_path):\n","                processed_img_list = load_data(label_path)\n","            else:\n","                processed_img_list = np.array([])\n","        all_data[category][label] = processed_img_list\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["# Function to sample 500 images from each label for training\n","def sample_images(data, num_samples=300):\n","    sampled_data = []\n","    sampled_labels = []\n","    for label, images in data.items():\n","        if len(images) >= num_samples:\n","            sampled_data.append(images[:num_samples])\n","            sampled_labels.append(np.full(num_samples, label))\n","        else:\n","            sampled_data.append(images)\n","            sampled_labels.append(np.full(len(images), label))\n","    sampled_data = np.concatenate(sampled_data, axis=0)\n","    sampled_labels = np.concatenate(sampled_labels, axis=0)\n","    return shuffle(sampled_data, sampled_labels)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["# Sample 500 images\n","train_data_sampled, train_labels_sampled = sample_images(all_data['train'])\n","val_data_sampled, val_labels_sampled = sample_images(all_data['val'])\n","test_data_sampled, test_labels_sampled = sample_images(all_data['test'])"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"WFTyhCa1R-EO"},"outputs":[],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# val_data_combined = []\n","# val_labels_combined = []\n","# test_data_combined = []\n","# test_labels_combined = []\n","\n","# for dataset in ['val', 'test']:\n","#     for label, images in all_data[dataset].items():\n","#         if dataset == 'val':\n","#             val_data_combined.append(images)\n","#             val_labels_combined.append(np.full(images.shape[0], label))\n","#         else:\n","#             test_data_combined.append(images)\n","#             test_labels_combined.append(np.full(images.shape[0], label))\n","\n","# val_data_combined = np.concatenate(val_data_combined, axis=0)\n","# val_labels_combined = np.concatenate(val_labels_combined, axis=0)\n","# test_data_combined = np.concatenate(test_data_combined, axis=0)\n","# test_labels_combined = np.concatenate(test_labels_combined, axis=0)\n","\n","# PyTorch 텐서로 변환\n","train_data_tensor = torch.tensor(train_data_sampled, dtype=torch.float32)\n","train_labels_tensor = torch.tensor(train_labels_sampled, dtype=torch.long)\n","val_data_tensor = torch.tensor(val_data_sampled, dtype=torch.float32)\n","val_labels_tensor = torch.tensor(val_labels_sampled, dtype=torch.long)\n","test_data_tensor = torch.tensor(test_data_sampled, dtype=torch.float32)\n","test_labels_tensor = torch.tensor(test_labels_sampled, dtype=torch.long)\n","\n","# PyTorch 데이터셋 및 데이터 로더 생성\n","train_dataset = TensorDataset(train_data_tensor, train_labels_tensor)\n","val_dataset = TensorDataset(val_data_tensor, val_labels_tensor)\n","test_dataset = TensorDataset(test_data_tensor, test_labels_tensor)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1717741457515,"user":{"displayName":"이규원","userId":"12166977002529024931"},"user_tz":-540},"id":"Aw9LJJbJUarh","outputId":"51fbeac4-7905-4baf-8fca-5b1550cf1b39"},"outputs":[{"data":{"text/plain":["(torch.Size([900, 128, 128]),\n"," torch.Size([900]),\n"," torch.Size([574, 128, 128]),\n"," torch.Size([574]))"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["train_data_tensor.shape,train_labels_tensor.shape ,test_data_tensor.shape, test_labels_tensor.shape"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1717741460186,"user":{"displayName":"이규원","userId":"12166977002529024931"},"user_tz":-540},"id":"MQpIZVdtUucs","outputId":"65a96da7-6088-4b23-9fd4-ffcf3e738bb4"},"outputs":[{"data":{"text/plain":["(torch.Size([433, 128, 128]),\n"," torch.Size([574, 128, 128]),\n"," torch.Size([433]),\n"," torch.Size([574]))"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["val_data_tensor.shape, test_data_tensor.shape, val_labels_tensor.shape, test_labels_tensor.shape"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"plZErbJ4U1xx"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\igyuw\\anaconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","c:\\Users\\igyuw\\anaconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Train loss: 1.011, Train Accuracy: 48.22%\n","Epoch 1, Validation loss: 0.989, Validation Accuracy: 47.81%\n","Training complete\n","Epoch 2, Train loss: 0.842, Train Accuracy: 62.11%\n","Epoch 2, Validation loss: 0.978, Validation Accuracy: 48.27%\n","Training complete\n","Epoch 3, Train loss: 0.729, Train Accuracy: 70.56%\n","Epoch 3, Validation loss: 1.060, Validation Accuracy: 44.34%\n","Training complete\n","Epoch 4, Train loss: 0.699, Train Accuracy: 72.67%\n","Epoch 4, Validation loss: 0.862, Validation Accuracy: 59.35%\n","Training complete\n","Epoch 5, Train loss: 0.646, Train Accuracy: 74.78%\n","Epoch 5, Validation loss: 0.960, Validation Accuracy: 53.12%\n","Training complete\n","Epoch 6, Train loss: 0.612, Train Accuracy: 75.00%\n","Epoch 6, Validation loss: 0.982, Validation Accuracy: 52.19%\n","Training complete\n","Epoch 7, Train loss: 0.561, Train Accuracy: 78.67%\n","Epoch 7, Validation loss: 1.065, Validation Accuracy: 45.96%\n","Training complete\n","Epoch 8, Train loss: 0.583, Train Accuracy: 75.00%\n","Epoch 8, Validation loss: 0.897, Validation Accuracy: 56.58%\n","Training complete\n","Epoch 9, Train loss: 0.545, Train Accuracy: 76.33%\n","Epoch 9, Validation loss: 0.799, Validation Accuracy: 62.12%\n","Training complete\n","Epoch 10, Train loss: 0.511, Train Accuracy: 80.00%\n","Epoch 10, Validation loss: 0.901, Validation Accuracy: 54.73%\n","Training complete\n","Epoch 11, Train loss: 0.527, Train Accuracy: 78.33%\n","Epoch 11, Validation loss: 0.858, Validation Accuracy: 58.89%\n","Training complete\n","Epoch 12, Train loss: 0.519, Train Accuracy: 79.00%\n","Epoch 12, Validation loss: 0.857, Validation Accuracy: 60.05%\n","Training complete\n","Epoch 13, Train loss: 0.495, Train Accuracy: 80.56%\n","Epoch 13, Validation loss: 0.956, Validation Accuracy: 52.66%\n","Training complete\n","Epoch 14, Train loss: 0.503, Train Accuracy: 81.33%\n","Epoch 14, Validation loss: 0.783, Validation Accuracy: 65.36%\n","Training complete\n","Epoch 15, Train loss: 0.471, Train Accuracy: 82.33%\n","Epoch 15, Validation loss: 1.023, Validation Accuracy: 49.88%\n","Training complete\n","Epoch 16, Train loss: 0.501, Train Accuracy: 80.33%\n","Epoch 16, Validation loss: 1.025, Validation Accuracy: 49.42%\n","Training complete\n","Epoch 17, Train loss: 0.469, Train Accuracy: 81.44%\n","Epoch 17, Validation loss: 0.860, Validation Accuracy: 59.35%\n","Training complete\n","Epoch 18, Train loss: 0.431, Train Accuracy: 82.78%\n","Epoch 18, Validation loss: 0.928, Validation Accuracy: 54.73%\n","Training complete\n","Epoch 19, Train loss: 0.409, Train Accuracy: 84.11%\n","Epoch 19, Validation loss: 0.865, Validation Accuracy: 58.89%\n","Training complete\n","Epoch 20, Train loss: 0.388, Train Accuracy: 85.89%\n","Epoch 20, Validation loss: 0.895, Validation Accuracy: 57.51%\n","Training complete\n","Epoch 21, Train loss: 0.427, Train Accuracy: 85.56%\n","Epoch 21, Validation loss: 0.842, Validation Accuracy: 58.66%\n","Training complete\n","Epoch 22, Train loss: 0.417, Train Accuracy: 84.22%\n","Epoch 22, Validation loss: 0.888, Validation Accuracy: 56.35%\n","Training complete\n","Epoch 23, Train loss: 0.417, Train Accuracy: 86.78%\n","Epoch 23, Validation loss: 0.918, Validation Accuracy: 57.97%\n","Training complete\n","Epoch 24, Train loss: 0.427, Train Accuracy: 83.44%\n","Epoch 24, Validation loss: 0.970, Validation Accuracy: 54.04%\n","Training complete\n","Epoch 25, Train loss: 0.427, Train Accuracy: 84.56%\n","Epoch 25, Validation loss: 0.975, Validation Accuracy: 53.35%\n","Training complete\n","Epoch 26, Train loss: 0.396, Train Accuracy: 85.44%\n","Epoch 26, Validation loss: 0.991, Validation Accuracy: 54.27%\n","Training complete\n","Epoch 27, Train loss: 0.394, Train Accuracy: 85.00%\n","Epoch 27, Validation loss: 1.315, Validation Accuracy: 42.49%\n","Training complete\n","Epoch 28, Train loss: 0.420, Train Accuracy: 83.11%\n","Epoch 28, Validation loss: 0.900, Validation Accuracy: 59.35%\n","Training complete\n","Epoch 29, Train loss: 0.455, Train Accuracy: 81.11%\n","Epoch 29, Validation loss: 1.162, Validation Accuracy: 48.73%\n","Training complete\n","Epoch 30, Train loss: 0.398, Train Accuracy: 83.89%\n","Epoch 30, Validation loss: 0.931, Validation Accuracy: 56.12%\n","Training complete\n","Test Accuracy: 56.97%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Define the number of output classes\n","num_classes = 3\n","\n","# Load pre-trained models and modify the final layer for transfer learning\n","def get_pretrained_model(model_name, num_classes):\n","    if model_name == 'resnet':\n","        model = models.resnet50(pretrained=True)\n","        model.fc = nn.Linear(model.fc.in_features, num_classes)\n","    elif model_name == 'densenet':\n","        model = models.densenet121(pretrained=True)\n","        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n","    elif model_name == 'vgg':\n","        model = models.vgg16(pretrained=True)\n","        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n","    else:\n","        raise ValueError('Unknown model name')\n","    \n","    return model\n","\n","# 사전학습 모델 설정\n","criterion = nn.CrossEntropyLoss()\n","model_name = 'densenet'  # or 'resnet' or 'vgg'\n","model = get_pretrained_model(model_name, num_classes)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","\n","# Freeze initial layers\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# Unfreeze the last layer\n","if model_name == 'resnet':\n","    for param in model.fc.parameters():\n","        param.requires_grad = True\n","elif model_name == 'densenet':\n","    for param in model.classifier.parameters():\n","        param.requires_grad = True\n","elif model_name == 'vgg':\n","    for param in model.classifier[6].parameters():\n","        param.requires_grad = True\n","\n","# Redefine optimizer to update only the last layer\n","optimizer = optim.Adam(filter(lambda x: x.requires_grad, model.parameters()), lr=0.001)\n","\n","# Training loop\n","num_epochs = 30\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","    for i, data in enumerate(train_loader, 0):\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        \n","        # Ensure inputs have the correct shape (N, C, H, W) and convert grayscale to RGB\n","        if inputs.ndim == 3:\n","            inputs = inputs.unsqueeze(1)  # Add channel dimension if missing\n","        if inputs.shape[1] == 1:\n","            inputs = inputs.repeat(1, 3, 1, 1)\n","        \n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_train += labels.size(0)\n","        correct_train += (predicted == labels).sum().item()\n","        \n","        if i % 100 == 99:\n","            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n","            running_loss = 0.0\n","\n","    train_loss = running_loss / len(train_loader)\n","    train_accuracy = 100 * correct_train / total_train\n","    \n","    model.eval()\n","    val_loss = 0.0\n","    correct_val = 0\n","    total_val = 0\n","    with torch.no_grad():\n","        for data in val_loader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            \n","            # Ensure images have the correct shape (N, C, H, W) and convert grayscale to RGB\n","            if images.ndim == 3:\n","                images = images.unsqueeze(1)  # Add channel dimension if missing\n","            if images.shape[1] == 1:\n","                images = images.repeat(1, 3, 1, 1)\n","            \n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_val += labels.size(0)\n","            correct_val += (predicted == labels).sum().item()\n","\n","    val_loss /= len(val_loader)\n","    val_accuracy = 100 * correct_val / total_val\n","    \n","    print(f'Epoch {epoch + 1}, Train loss: {train_loss:.3f}, Train Accuracy: {train_accuracy:.2f}%')\n","    print(f'Epoch {epoch + 1}, Validation loss: {val_loss:.3f}, Validation Accuracy: {val_accuracy:.2f}%')\n","    print('Training complete')\n","\n","# Testing phase\n","model.eval()\n","correct = 0\n","total = 0\n","all_labels = []\n","all_predictions = []\n","with torch.no_grad():\n","    for data in test_loader:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","                                                   \n","        if images.ndim == 3:\n","            images = images.unsqueeze(1)  # Add channel dimension if missing\n","        if images.shape[1] == 1:\n","            images = images.repeat(1, 3, 1, 1)\n","        \n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        all_labels.extend(labels.cpu().numpy())\n","        all_predictions.extend(predicted.cpu().numpy())\n","\n","test_accuracy = 100 * correct / total\n","print(f'Test Accuracy: {test_accuracy:.2f}%')\n"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Confusion Matrix:\n","[[195  91  14]\n"," [ 76 109  38]\n"," [  1  27  23]]\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1000x800 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["from sklearn.metrics import confusion_matrix\n","\n","# Confusion matrix\n","conf_matrix = confusion_matrix(all_labels, all_predictions)\n","print('Confusion Matrix:')\n","print(conf_matrix)\n","\n","# Plotting confusion matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=range(num_classes), yticklabels=range(num_classes))\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","# 0 : 639\n","# 1 : 296\n","# 2 : 447\n","# 3 : 223\n","# 4 : 51"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["# # Define the number of output classes\n","# num_classes = 5\n","\n","# # Load pre-trained models and modify the final layer for transfer learning\n","# def get_pretrained_model(model_name, num_classes):\n","#     if model_name == 'resnet':\n","#         model = models.resnet18(pretrained=True)\n","#         model.fc = nn.Linear(model.fc.in_features, num_classes)\n","#     elif model_name == 'densenet':\n","#         model = models.densenet121(pretrained=True)\n","#         model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n","#     elif model_name == 'vgg':\n","#         model = models.vgg16(pretrained=True)\n","#         model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n","#     else:\n","#         raise ValueError('Unknown model name')\n","    \n","#     return model\n","\n","# # 사전학습 모델 설정\n","# model_name = 'resnet'  # or 'densenet' or 'vgg'\n","# model = get_pretrained_model(model_name, num_classes)\n","# model = model.to(device)\n","\n","# # Freeze initial layers\n","# for param in model.parameters():\n","#     param.requires_grad = False\n","\n","# # Unfreeze the last layer\n","# if model_name == 'resnet':\n","#     for param in model.fc.parameters():\n","#         param.requires_grad = True\n","# elif model_name == 'densenet':\n","#     for param in model.classifier.parameters():\n","#         param.requires_grad = True\n","# elif model_name == 'vgg':\n","#     for param in model.classifier[6].parameters():\n","#         param.requires_grad = True\n","\n","# # Redefine optimizer to update only the last layer\n","# optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n","\n","# # Training loop (same as before)\n","# num_epochs = 30\n","# for epoch in range(num_epochs):\n","#     model.train()\n","#     running_loss = 0.0\n","#     for i, data in enumerate(train_loader, 0):\n","#         inputs, labels = data\n","#         inputs, labels = inputs.to(device), labels.to(device)\n","#         inputs = inputs.unsqueeze(1)  # Add channel dimension for grayscale images\n","#         optimizer.zero_grad()\n","#         outputs = model(inputs)\n","#         loss = criterion(outputs, labels)\n","#         loss.backward()\n","#         optimizer.step()\n","\n","#         running_loss += loss.item()\n","#         if i % 100 == 99:\n","#             print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n","#             running_loss = 0.0\n","\n","#     model.eval()\n","#     val_loss = 0.0\n","#     correct = 0\n","#     total = 0\n","#     with torch.no_grad():\n","#         for data in val_loader:\n","#             images, labels = data\n","#             inputs, labels = inputs.to(device), labels.to(device)\n","#             images = images.unsqueeze(1)\n","#             outputs = model(images)\n","#             loss = criterion(outputs, labels)\n","#             val_loss += loss.item()\n","#             _, predicted = torch.max(outputs.data, 1)\n","#             total += labels.size(0)\n","#             correct += (predicted == labels).sum().item()\n","\n","#     print(f'Epoch {epoch + 1}, Validation loss: {val_loss / len(val_loader):.3f}, Accuracy: {100 * correct / total:.2f}%')\n","\n","# print('Training complete')\n","\n","# # Testing phase (same as before)\n","# model.eval()\n","# correct = 0\n","# total = 0\n","# with torch.no_grad():\n","#     for data in test_loader:\n","#         images, labels = data\n","#         inputs, labels = inputs.to(device), labels.to(device)\n","#         outputs = model(images)\n","#         _, predicted = torch.max(outputs.data, 1)\n","#         total += labels.size(0)\n","#         correct += (predicted == labels).sum().item()\n","\n","# print(f'Test Accuracy: {100 * correct / total:.2f}%')\n"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"7Wybk5F-V7de"},"outputs":[],"source":["# # 테스트 단계\n","# model.eval()\n","# correct = 0\n","# total = 0\n","# with torch.no_grad():\n","#     for data in test_loader:\n","#         images, labels = data\n","#         inputs, labels = inputs.to(device), labels.to(device)\n","#         outputs = model(images)\n","#         _, predicted = torch.max(outputs.data, 1)\n","#         total += labels.size(0)\n","#         correct += (predicted == labels).sum().item()\n","\n","# print(f'Test Accuracy: {100 * correct / total:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyM18Nh3+xFB72VFV2xhHYNL","gpuType":"T4","mount_file_id":"181UmXhZRdtJpBK4YXbMd7VE_qHlKiyek","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
