{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['train', 'test', 'val', 'auto_test'] # 전처리된 데이터셋을 훈련용, 평가용, 검증용으로 구분\n",
    "data_dir = path+'/osteoarthritis/'\n",
    "# device = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu') # Mac OS\n",
    "device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 함수들\n",
    "def resize_image(img, size=(128, 128)):\n",
    "    return cv2.resize(img, size)\n",
    "\n",
    "def clahe_image(img):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(img)\n",
    "\n",
    "def normalize_img(img):\n",
    "    return cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "def denoise_img(img):\n",
    "    return cv2.fastNlMeansDenoising(img, None, 30, 7, 21)\n",
    "\n",
    "def adjust_gamma(image, gamma=0.5):\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def crop_knee(image, crop_height, crop_width):\n",
    "    h, w = image.shape[:2]\n",
    "    center = (h // 2, w // 2)\n",
    "    cropped_img = image[\n",
    "        center[0] - crop_height // 2 : center[0] + crop_height // 2,\n",
    "        center[1] - crop_width // 2 : center[1] + crop_width // 2\n",
    "    ]\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 95\u001b[0m\n\u001b[0;32m     92\u001b[0m images \u001b[38;5;241m=\u001b[39m augment_images(data_dir, \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Display images to verify\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     96\u001b[0m     random_images \u001b[38;5;241m=\u001b[39m images[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m5\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[0;32m     98\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Data augmentation settings\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=5,  # Increased for more variety\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def augment_images(data_dir, label, augment_count=600, gamma=0.5):\n",
    "    label_path = os.path.join(data_dir, 'train', str(label))\n",
    "    augmented_dir = os.path.join(label_path, 'augmented')\n",
    "    os.makedirs(augmented_dir, exist_ok=True)\n",
    "\n",
    "    img_names = os.listdir(label_path)\n",
    "    img_names = [name for name in img_names if os.path.isfile(os.path.join(label_path, name))]\n",
    "    generated_count = 0\n",
    "\n",
    "    while generated_count < augment_count:\n",
    "        img_name = np.random.choice(img_names)\n",
    "        img_path = os.path.join(label_path, img_name)\n",
    "        try:\n",
    "            img = load_img(img_path, color_mode='grayscale', target_size=(224, 224))\n",
    "            img = img_to_array(img).astype('uint8')\n",
    "            img = np.squeeze(img, axis=-1)\n",
    "            img = adjust_gamma(img, gamma=gamma)\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "\n",
    "            for batch in datagen.flow(img, batch_size=1, save_to_dir=augmented_dir, save_prefix='aug', save_format='png'):\n",
    "                generated_count += 1\n",
    "                break\n",
    "        except PermissionError:\n",
    "            print(f\"Permission denied: Unable to access file {img_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {img_path}: {e}\")\n",
    "\n",
    "# def load_data(data_dir):\n",
    "#     images = []\n",
    "#     for img_name in os.listdir(data_dir):\n",
    "#         img_path = os.path.join(data_dir, img_name)\n",
    "#         if os.path.isfile(img_path):\n",
    "#             img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "#             if img is not None:\n",
    "#                 img = resize_image(img)\n",
    "#                 img = crop_knee(img, 320, 400)\n",
    "#                 img = clahe_image(img)\n",
    "#                 img = normalize_img(img)\n",
    "#                 images.append(img)\n",
    "#     return np.array(images)\n",
    "\n",
    "# def load_and_augment_data(data_dir, label):\n",
    "#     label_path = os.path.join(data_dir, 'train', str(label))\n",
    "#     augmented_dir = os.path.join(label_path, 'augmented')\n",
    "\n",
    "#     images = []\n",
    "#     for img_name in os.listdir(label_path):\n",
    "#         img_path = os.path.join(label_path, img_name)\n",
    "#         if img_name.endswith('.png') and os.path.isfile(img_path):\n",
    "#             img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "#             if img is not None:\n",
    "#                 img = resize_image(img)\n",
    "#                 img = crop_knee(img, 320, 400)\n",
    "#                 img = clahe_image(img)\n",
    "#                 img = normalize_img(img)\n",
    "#                 images.append(img)\n",
    "    \n",
    "#     if os.path.exists(augmented_dir):\n",
    "#         for img_name in os.listdir(augmented_dir):\n",
    "#             img_path = os.path.join(augmented_dir, img_name)\n",
    "#             if img_name.endswith('.png') and os.path.isfile(img_path):\n",
    "#                 img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "#                 if img is not None:\n",
    "#                     img = resize_image(img)\n",
    "#                     img = crop_knee(img, 320, 400)\n",
    "#                     img = clahe_image(img)\n",
    "#                     img = normalize_img(img)\n",
    "#                     images.append(img)\n",
    "    \n",
    "#     return np.array(images)\n",
    "\n",
    "# # Example usage:\n",
    "images = augment_images(data_dir, 4)\n",
    "\n",
    "# Display images to verify\n",
    "if images.size > 0:\n",
    "    random_images = images[np.random.choice(images.shape[0], 5, replace=False)]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, img in enumerate(random_images):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No images found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation settings\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=5,  # Increased for more variety\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def augment_images(data_dir, label, augment_count=600):\n",
    "    label_path = os.path.join(data_dir, 'train', str(label))\n",
    "    augmented_dir = os.path.join(label_path, 'augmented')\n",
    "    os.makedirs(augmented_dir, exist_ok=True)\n",
    "\n",
    "    img_names = os.listdir(label_path)\n",
    "    img_names = [name for name in img_names if os.path.isfile(os.path.join(label_path, name))]\n",
    "    generated_count = 0\n",
    "\n",
    "    while generated_count < augment_count:\n",
    "        img_name = np.random.choice(img_names)\n",
    "        img_path = os.path.join(label_path, img_name)\n",
    "        try:\n",
    "            img = load_img(img_path, color_mode='grayscale', target_size=(224, 224))\n",
    "            img = img_to_array(img)\n",
    "            img = img.reshape((1,) + img.shape)\n",
    "\n",
    "            for batch in datagen.flow(img, batch_size=1, save_to_dir=augmented_dir, save_prefix='aug', save_format='png'):\n",
    "                generated_count += 1\n",
    "                break  # 한 장만 생성하고 반복문 탈출\n",
    "        except PermissionError:\n",
    "            print(f\"Permission denied: Unable to access file {img_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {img_path}: {e}\")\n",
    "\n",
    "# # Augment images in label 4\n",
    "data_dir = path+'/osteoarthritis/train/'  # 적절한 데이터 디렉토리로 변경\n",
    "augment_images(data_dir, 4)\n",
    "\n",
    "# Display augmented images\n",
    "augmented_img_paths = os.listdir(os.path.join(data_dir, 'train', '4', 'augmented'))\n",
    "augmented_img_paths = shuffle(augmented_img_paths)[:6]  # 무작위로 6개 선택\n",
    "\n",
    "for i, img_name in enumerate(augmented_img_paths):\n",
    "    img_path = os.path.join(data_dir, 'train', '4', 'augmented', img_name)\n",
    "    img = load_img(img_path, color_mode='grayscale', target_size=(128, 128))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f'Augmented Image {i + 1}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
